{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc98343",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "print(os.getenv('TF_GPU_ALLOCATOR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c456b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe754c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-06T18:18:39.589217Z",
     "start_time": "2022-07-06T18:18:39.472918Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7e02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import importlib.util\n",
    "import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf862c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "Listing all GPU resources:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pbnn_utils import *\n",
    "#from pbnn_model import *\n",
    "#from pbnn_model import ModelLoader\n",
    "#from pbnn_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737423c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c1e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec13dc42",
   "metadata": {},
   "source": [
    "### Uncertainty for Medical Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5ae20",
   "metadata": {},
   "source": [
    "Analyzing the Quality and Challenges of Uncertainty Estimations for Brain Tumor Segmentation : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7156850/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db2e78",
   "metadata": {},
   "source": [
    "### Additional Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9924b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-06T18:20:47.971386Z",
     "start_time": "2022-07-06T18:20:47.966469Z"
    }
   },
   "outputs": [],
   "source": [
    "## Will send the PDF of the work separately on slack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a161a",
   "metadata": {},
   "source": [
    "Based on Snehal's paper, it seems like Partial Bayesian Neural Networks offer a way to characterize (and communicate) the machine learning model's uncertainty about the tumor predictions in a way that is computationally efficient. Her process has four steps to acheive a final pBNN (partial bayesian neural network). *These will hopefully be explained further soon*\n",
    "\n",
    "(1) Access deterministic model\n",
    "(2) Conduct Sensitivity Analysis (on each layer) via Dice Coefficient\n",
    "(3) Model Layer Selection (based on SA)\n",
    "(4) Partially Bayesian Neural Network -- train both bayes and deterministic parameters(?)\n",
    "\n",
    "I am not totally sure what *we* are trying to do...whether it be replicate her experiment or implement her findings on this specific neural network (my guess is this...)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1002041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4a34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a694fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71717256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aea342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pbnn_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd38bd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "Listing all GPU resources:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "0.17.0\n",
      "------------------------------\n",
      "Constructing model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 15:22:38.407719: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-13 15:22:39.590566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10543 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:03:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scolando/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow_probability/python/layers/util.py:95: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  loc = add_variable_fn(\n",
      "/home/scolando/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow_probability/python/layers/util.py:105: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  untransformed_scale = add_variable_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input size: (None, 144, 144, 4)\n",
      "Output size: (None, 144, 144, 1)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model summary:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 144, 144, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " encoder_1_a (Conv2DFlipout)    (None, 144, 144, 32  2368        ['input_layer[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " encoder_1_b (Conv2D)           (None, 144, 144, 32  9248        ['encoder_1_a[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " downsample_1 (MaxPooling2D)    (None, 72, 72, 32)   0           ['encoder_1_b[0][0]']            \n",
      "                                                                                                  \n",
      " encoder_2_a (Conv2D)           (None, 72, 72, 64)   18496       ['downsample_1[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_2_b (Conv2D)           (None, 72, 72, 64)   36928       ['encoder_2_a[0][0]']            \n",
      "                                                                                                  \n",
      " downsample_2 (MaxPooling2D)    (None, 36, 36, 64)   0           ['encoder_2_b[0][0]']            \n",
      "                                                                                                  \n",
      " encoder_3_a (Conv2D)           (None, 36, 36, 128)  73856       ['downsample_2[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_3_b (Conv2D)           (None, 36, 36, 128)  147584      ['encoder_3_a[0][0]']            \n",
      "                                                                                                  \n",
      " downsample_3 (MaxPooling2D)    (None, 18, 18, 128)  0           ['encoder_3_b[0][0]']            \n",
      "                                                                                                  \n",
      " encoder_4_a (Conv2D)           (None, 18, 18, 256)  295168      ['downsample_3[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_4_b (Conv2D)           (None, 18, 18, 256)  590080      ['encoder_4_a[0][0]']            \n",
      "                                                                                                  \n",
      " downsample_4 (MaxPooling2D)    (None, 9, 9, 256)    0           ['encoder_4_b[0][0]']            \n",
      "                                                                                                  \n",
      " encoder_5_a (Conv2D)           (None, 9, 9, 512)    1180160     ['downsample_4[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_5_b (Conv2D)           (None, 9, 9, 512)    2359808     ['encoder_5_a[0][0]']            \n",
      "                                                                                                  \n",
      " upsample_4 (UpSampling2D)      (None, 18, 18, 512)  0           ['encoder_5_b[0][0]']            \n",
      "                                                                                                  \n",
      " concat_4 (Concatenate)         (None, 18, 18, 768)  0           ['upsample_4[0][0]',             \n",
      "                                                                  'encoder_4_b[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_4_a (Conv2D)           (None, 18, 18, 256)  1769728     ['concat_4[0][0]']               \n",
      "                                                                                                  \n",
      " decoder_4_b (Conv2D)           (None, 18, 18, 256)  590080      ['decoder_4_a[0][0]']            \n",
      "                                                                                                  \n",
      " upsample_3 (UpSampling2D)      (None, 36, 36, 256)  0           ['decoder_4_b[0][0]']            \n",
      "                                                                                                  \n",
      " concat_3 (Concatenate)         (None, 36, 36, 384)  0           ['upsample_3[0][0]',             \n",
      "                                                                  'encoder_3_b[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_3_a (Conv2D)           (None, 36, 36, 128)  442496      ['concat_3[0][0]']               \n",
      "                                                                                                  \n",
      " decoder_3_b (Conv2D)           (None, 36, 36, 128)  147584      ['decoder_3_a[0][0]']            \n",
      "                                                                                                  \n",
      " upsample_2 (UpSampling2D)      (None, 72, 72, 128)  0           ['decoder_3_b[0][0]']            \n",
      "                                                                                                  \n",
      " concat_2 (Concatenate)         (None, 72, 72, 192)  0           ['upsample_2[0][0]',             \n",
      "                                                                  'encoder_2_b[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_2_a (Conv2D)           (None, 72, 72, 64)   110656      ['concat_2[0][0]']               \n",
      "                                                                                                  \n",
      " decoder_2_b (Conv2D)           (None, 72, 72, 64)   36928       ['decoder_2_a[0][0]']            \n",
      "                                                                                                  \n",
      " upsample_1 (UpSampling2D)      (None, 144, 144, 64  0           ['decoder_2_b[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concat_1 (Concatenate)         (None, 144, 144, 96  0           ['upsample_1[0][0]',             \n",
      "                                )                                 'encoder_1_b[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_1_a (Conv2D)           (None, 144, 144, 32  27680       ['concat_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_1_b (Conv2D)           (None, 144, 144, 32  9248        ['decoder_1_a[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " output_layer (Conv2D)          (None, 144, 144, 1)  33          ['decoder_1_b[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "Total params: 7,848,129\n",
      "Trainable params: 7,848,129\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model losses:\n",
      "[<tf.Tensor: shape=(), dtype=float32, numpy=10597.722>, <tf.Tensor: shape=(), dtype=float32, numpy=296.58282>]\n",
      "------------------------------\n",
      "Loading training and testing data...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 15:22:58.534685: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15957098496 exceeds 10% of free system memory.\n",
      "2022-07-13 15:23:23.509663: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 14.86GiB (rounded to 15957098496)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-07-13 15:23:23.509719: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-07-13 15:23:23.509743: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 47, Chunks in use: 47. 11.8KiB allocated for chunks. 11.8KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509758: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509769: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 5, Chunks in use: 5. 5.2KiB allocated for chunks. 5.2KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509779: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 2, Chunks in use: 2. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509790: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 5, Chunks in use: 4. 22.5KiB allocated for chunks. 18.0KiB in use in bin. 18.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509801: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509811: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509822: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 3, Chunks in use: 2. 131.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509834: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 3, Chunks in use: 1. 216.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509845: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 4, Chunks in use: 3. 612.0KiB allocated for chunks. 468.0KiB in use in bin. 396.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509857: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 2, Chunks in use: 1. 720.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509868: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 4, Chunks in use: 3. 2.39MiB allocated for chunks. 1.83MiB in use in bin. 1.55MiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509883: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 2.81MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509893: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 3. 9.56MiB allocated for chunks. 7.31MiB in use in bin. 6.19MiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509904: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 11.25MiB allocated for chunks. 11.25MiB in use in bin. 11.25MiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509914: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509929: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 0. 18.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509938: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509947: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509956: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509966: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 10.24GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-13 15:23:23.509980: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 14.86GiB was 256.00MiB, Chunk State: \n",
      "2022-07-13 15:23:23.509996: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 10.24GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 6.75MiB | Requested Size: 6.75MiB | in_use: 1 | bin_num: -1\n",
      "2022-07-13 15:23:23.510005: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 11055857664\n",
      "2022-07-13 15:23:23.514889: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000000 of size 256 next 1\n",
      "2022-07-13 15:23:23.514908: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000100 of size 1280 next 2\n",
      "2022-07-13 15:23:23.514917: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000600 of size 256 next 3\n",
      "2022-07-13 15:23:23.514925: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000700 of size 256 next 4\n",
      "2022-07-13 15:23:23.514932: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000800 of size 256 next 5\n",
      "2022-07-13 15:23:23.514940: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000900 of size 256 next 8\n",
      "2022-07-13 15:23:23.514949: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000a00 of size 512 next 37\n",
      "2022-07-13 15:23:23.514957: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4000c00 of size 1024 next 42\n",
      "2022-07-13 15:23:23.514965: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4001000 of size 256 next 43\n",
      "2022-07-13 15:23:23.514972: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4001100 of size 256 next 44\n",
      "2022-07-13 15:23:23.514980: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4001200 of size 1024 next 45\n",
      "2022-07-13 15:23:23.514988: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4001600 of size 2048 next 50\n",
      "2022-07-13 15:23:23.514995: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4001e00 of size 256 next 51\n",
      "2022-07-13 15:23:23.515003: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4001f00 of size 256 next 52\n",
      "2022-07-13 15:23:23.515010: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4002000 of size 3072 next 6\n",
      "2022-07-13 15:23:23.515018: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4002c00 of size 4608 next 7\n",
      "2022-07-13 15:23:23.515026: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4003e00 of size 256 next 11\n",
      "2022-07-13 15:23:23.515033: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4003f00 of size 256 next 12\n",
      "2022-07-13 15:23:23.515041: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004000 of size 256 next 14\n",
      "2022-07-13 15:23:23.515051: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004100 of size 256 next 16\n",
      "2022-07-13 15:23:23.515059: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004200 of size 256 next 17\n",
      "2022-07-13 15:23:23.515067: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004300 of size 256 next 18\n",
      "2022-07-13 15:23:23.515074: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004400 of size 256 next 19\n",
      "2022-07-13 15:23:23.515081: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004500 of size 256 next 20\n",
      "2022-07-13 15:23:23.515088: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004600 of size 256 next 21\n",
      "2022-07-13 15:23:23.515096: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004700 of size 256 next 22\n",
      "2022-07-13 15:23:23.515103: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004800 of size 256 next 27\n",
      "2022-07-13 15:23:23.515110: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004900 of size 256 next 28\n",
      "2022-07-13 15:23:23.515125: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004a00 of size 256 next 29\n",
      "2022-07-13 15:23:23.515133: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004b00 of size 256 next 30\n",
      "2022-07-13 15:23:23.515140: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004c00 of size 512 next 35\n",
      "2022-07-13 15:23:23.515148: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004e00 of size 256 next 36\n",
      "2022-07-13 15:23:23.515155: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4004f00 of size 256 next 9\n",
      "2022-07-13 15:23:23.515162: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4005000 of size 4608 next 10\n",
      "2022-07-13 15:23:23.515170: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4006200 of size 4608 next 13\n",
      "2022-07-13 15:23:23.515177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4007400 of size 4608 next 15\n",
      "2022-07-13 15:23:23.515185: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4008600 of size 256 next 53\n",
      "2022-07-13 15:23:23.515192: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4008700 of size 256 next 56\n",
      "2022-07-13 15:23:23.515200: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4008800 of size 1024 next 57\n",
      "2022-07-13 15:23:23.515207: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4008c00 of size 1024 next 59\n",
      "2022-07-13 15:23:23.515215: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009000 of size 256 next 61\n",
      "2022-07-13 15:23:23.515222: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009100 of size 256 next 62\n",
      "2022-07-13 15:23:23.515229: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009200 of size 512 next 63\n",
      "2022-07-13 15:23:23.515237: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009400 of size 512 next 65\n",
      "2022-07-13 15:23:23.515244: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009600 of size 256 next 67\n",
      "2022-07-13 15:23:23.515251: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009700 of size 256 next 68\n",
      "2022-07-13 15:23:23.515259: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009800 of size 256 next 69\n",
      "2022-07-13 15:23:23.515266: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009900 of size 256 next 71\n",
      "2022-07-13 15:23:23.515273: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009a00 of size 256 next 73\n",
      "2022-07-13 15:23:23.515281: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009b00 of size 256 next 74\n",
      "2022-07-13 15:23:23.515288: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009c00 of size 256 next 75\n",
      "2022-07-13 15:23:23.515296: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009d00 of size 256 next 77\n",
      "2022-07-13 15:23:23.515304: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009e00 of size 256 next 79\n",
      "2022-07-13 15:23:23.515311: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4009f00 of size 256 next 80\n",
      "2022-07-13 15:23:23.515319: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a000 of size 256 next 81\n",
      "2022-07-13 15:23:23.515326: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a100 of size 256 next 82\n",
      "2022-07-13 15:23:23.515333: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a200 of size 256 next 83\n",
      "2022-07-13 15:23:23.515341: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a300 of size 256 next 84\n",
      "2022-07-13 15:23:23.515353: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a400 of size 256 next 85\n",
      "2022-07-13 15:23:23.515361: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a500 of size 256 next 86\n",
      "2022-07-13 15:23:23.515368: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400a600 of size 256 next 88\n",
      "2022-07-13 15:23:23.515376: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd400a700 of size 4608 next 91\n",
      "2022-07-13 15:23:23.515383: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd400b900 of size 256 next 90\n",
      "2022-07-13 15:23:23.515391: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd400ba00 of size 60416 next 24\n",
      "2022-07-13 15:23:23.515399: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd401a600 of size 36864 next 23\n",
      "2022-07-13 15:23:23.515406: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd4023600 of size 73728 next 26\n",
      "2022-07-13 15:23:23.515414: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4035600 of size 73728 next 25\n",
      "2022-07-13 15:23:23.515422: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4047600 of size 36864 next 78\n",
      "2022-07-13 15:23:23.515429: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd4050600 of size 73728 next 76\n",
      "2022-07-13 15:23:23.515438: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4062600 of size 184320 next 32\n",
      "2022-07-13 15:23:23.515446: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd408f600 of size 147456 next 31\n",
      "2022-07-13 15:23:23.515454: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd40b3600 of size 147456 next 72\n",
      "2022-07-13 15:23:23.515461: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd40d7600 of size 147456 next 34\n",
      "2022-07-13 15:23:23.515469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd40fb600 of size 294912 next 33\n",
      "2022-07-13 15:23:23.515477: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd4143600 of size 442368 next 70\n",
      "2022-07-13 15:23:23.515488: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd41af600 of size 737280 next 39\n",
      "2022-07-13 15:23:23.515497: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4263600 of size 589824 next 38\n",
      "2022-07-13 15:23:23.515505: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd42f3600 of size 589824 next 66\n",
      "2022-07-13 15:23:23.515512: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd4383600 of size 589824 next 41\n",
      "2022-07-13 15:23:23.515520: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4413600 of size 1179648 next 40\n",
      "2022-07-13 15:23:23.515528: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd4533600 of size 1769472 next 64\n",
      "2022-07-13 15:23:23.515536: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd46e3600 of size 2949120 next 47\n",
      "2022-07-13 15:23:23.515544: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd49b3600 of size 2359296 next 46\n",
      "2022-07-13 15:23:23.515553: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd4bf3600 of size 2359296 next 60\n",
      "2022-07-13 15:23:23.515560: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd4e33600 of size 2359296 next 49\n",
      "2022-07-13 15:23:23.515568: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd5073600 of size 4718592 next 48\n",
      "2022-07-13 15:23:23.515575: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd54f3600 of size 18874368 next 55\n",
      "2022-07-13 15:23:23.515583: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd66f3600 of size 9437184 next 54\n",
      "2022-07-13 15:23:23.515591: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 2affd6ff3600 of size 7077888 next 58\n",
      "2022-07-13 15:23:23.515599: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 2affd76b3600 of size 10998499840 next 18446744073709551615\n",
      "2022-07-13 15:23:23.515607: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-07-13 15:23:23.515619: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 47 Chunks of size 256 totalling 11.8KiB\n",
      "2022-07-13 15:23:23.515629: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2022-07-13 15:23:23.515637: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 1024 totalling 4.0KiB\n",
      "2022-07-13 15:23:23.515646: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-07-13 15:23:23.515654: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2048 totalling 2.0KiB\n",
      "2022-07-13 15:23:23.515662: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2022-07-13 15:23:23.515671: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 4608 totalling 18.0KiB\n",
      "2022-07-13 15:23:23.515680: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 36864 totalling 72.0KiB\n",
      "2022-07-13 15:23:23.515689: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2022-07-13 15:23:23.515698: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 147456 totalling 288.0KiB\n",
      "2022-07-13 15:23:23.515707: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 184320 totalling 180.0KiB\n",
      "2022-07-13 15:23:23.515716: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2022-07-13 15:23:23.515724: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 589824 totalling 1.12MiB\n",
      "2022-07-13 15:23:23.515733: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 737280 totalling 720.0KiB\n",
      "2022-07-13 15:23:23.515742: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2022-07-13 15:23:23.515750: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 2359296 totalling 4.50MiB\n",
      "2022-07-13 15:23:23.515758: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2949120 totalling 2.81MiB\n",
      "2022-07-13 15:23:23.515767: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4718592 totalling 4.50MiB\n",
      "2022-07-13 15:23:23.515775: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 7077888 totalling 6.75MiB\n",
      "2022-07-13 15:23:23.515784: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 9437184 totalling 9.00MiB\n",
      "2022-07-13 15:23:23.515793: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 31.44MiB\n",
      "2022-07-13 15:23:23.515802: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 11055857664 memory_limit_: 11055857664 available bytes: 0 curr_region_allocation_bytes_: 22111715328\n",
      "2022-07-13 15:23:23.515817: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                     11055857664\n",
      "InUse:                        32962560\n",
      "MaxInUse:                     44824576\n",
      "NumAllocs:                         177\n",
      "MaxAllocSize:                 11796480\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-07-13 15:23:23.515834: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *___________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpbnn_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/Group2_Uncertainty/pbnn_train.py:66\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training and testing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m Xy_train \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_images.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(np\u001b[38;5;241m.\u001b[39mload(DATA_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_labels.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))))\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(np.load(DATA_PATH + 'train_patients.npy')))).cache().batch(BATCH_SIZE).prefetch(2) #,\u001b[39;00m\n\u001b[1;32m     69\u001b[0m                                \u001b[38;5;66;03m#tf.data.Dataset.from_tensor_slices(np.load(DATA_PATH + 'msks_train.npy')))).cache().batch(BATCH_SIZE).prefetch(2)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m Xy_test \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(np\u001b[38;5;241m.\u001b[39mload(DATA_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_images.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)), tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(np\u001b[38;5;241m.\u001b[39mload(DATA_PATH \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_labels.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))))\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m#,\u001b[39;00m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:809\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    733\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4551\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4550\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4551\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4552\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m   4553\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:125\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    124\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 125\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1631\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1632\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1633\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1640\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1643\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/BDSI_2022_ML/BdsiEnv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from pbnn_train import * #running out of memory rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929d081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    model = ModelLoader.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv('LAYER_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ROOT_PATH + \"/Group2_Uncertainty\" + \"/pbnn_model\"\n",
    "\n",
    "importlib.util.spec_from_file_location(MODEL_PATH, MODEL_PATH + \".py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'layers'\n",
    "value = os.getenv(key)\n",
    "  \n",
    "# Print the value of 'HOME'\n",
    "# environment variable\n",
    "print(\"Value of 'HOME' environment variable :\", value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1944f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "path = '/scratch/bdsi_root/bdsi1/scolando/'\n",
    "folders = ('train_labels/', 'train_images/')\n",
    "file_names = []\n",
    "for folder in folders:\n",
    "    for filename in os.listdir(path + folder):\n",
    "        file_names.append(filename)\n",
    "        \n",
    "file_names.sort()\n",
    "\n",
    "print(file_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column1 = []\n",
    "column2 = []\n",
    "\n",
    "for filenames in file_names:\n",
    "    if \"image\" in filenames:\n",
    "        column1.append(filenames)\n",
    "    else:\n",
    "        column2.append(filenames)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"train_image\": column1,\n",
    "     \"train_label\": column2,\n",
    "     \"index\":range(0,167)\n",
    "})\n",
    "\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "train_image_list = []\n",
    "train_label_list = []\n",
    "\n",
    "for value in df['train_label']:\n",
    "    train_label_list.append(value)\n",
    "for value in df['train_image']:\n",
    "    train_image_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path1 = '/scratch/bdsi_root/bdsi1/scolando/train_images/'\n",
    "train_images = []\n",
    "\n",
    "for filename in train_image_list:\n",
    "    f = os.path.join(path1, filename)\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "        patient_image=np.load(f).flatten().astype(float)\n",
    "        train_images.append(patient_image)\n",
    "        \n",
    "path2 = '/scratch/bdsi_root/bdsi1/scolando/train_labels/'\n",
    "train_labels = []\n",
    "\n",
    "for filename in train_label_list:\n",
    "    f = os.path.join(path2, filename)\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "        patient_label=np.load(f).flatten().astype(float)\n",
    "        train_labels.append(patient_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "\n",
    "np.save(\"train_images\", train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99244eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "\n",
    "np.save(\"train_labels\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4899e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "path = '/scratch/bdsi_root/bdsi1/scolando/'\n",
    "folders = ('test_labels/', 'test_images/')\n",
    "file_names1 = []\n",
    "for folder in folders:\n",
    "    for filename in os.listdir(path + folder):\n",
    "        file_names1.append(filename)\n",
    "        \n",
    "file_names1.sort()\n",
    "\n",
    "#random.shuffle(file_names)\n",
    "print(file_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfd8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c18692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column1_test = []\n",
    "column2_test = []\n",
    "\n",
    "for filenames in file_names1:\n",
    "    if \"image\" in filenames:\n",
    "        column1_test.append(filenames)\n",
    "    elif \"label\" in filenames:\n",
    "        column2_test.append(filenames)\n",
    "    else:\n",
    "        print(filenames)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"test_image\": column1_test,\n",
    "     \"test_label\": column2_test,\n",
    "     \"index\":range(0,39)\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "test_image_list = []\n",
    "test_label_list = []\n",
    "\n",
    "for value in df['test_label']:\n",
    "    test_label_list.append(value)\n",
    "for value in df['test_image']:\n",
    "    test_image_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path3 = '/scratch/bdsi_root/bdsi1/scolando/test_images/'\n",
    "test_images = []\n",
    "\n",
    "for filename in test_image_list:\n",
    "    f = os.path.join(path3, filename)\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "        patient_image=np.load(f).flatten().astype(float)\n",
    "        test_images.append(patient_image)\n",
    "        \n",
    "path4 = '/scratch/bdsi_root/bdsi1/scolando/test_labels/'\n",
    "test_labels = []\n",
    "\n",
    "for filename in test_label_list:\n",
    "    f = os.path.join(path4, filename)\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "        patient_label=np.load(f).flatten().astype(float)\n",
    "        test_labels.append(patient_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1475e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "\n",
    "np.save(\"test_images\", test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "\n",
    "np.save(\"test_labels\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51279a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585fca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BdsiEnv",
   "language": "python",
   "name": "bdsienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
